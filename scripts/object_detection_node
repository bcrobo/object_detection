#!/usr/bin/python

import roslib
import rospy
from sensor_msgs.msg import Image
from object_detection.msg import ObjectArray, Object
from cv_bridge import CvBridge, CvBridgeError

import tensorflow as tf
import numpy as np
import cv2
import itertools

# Import utilities
from utils import label_map_util
from utils import visualization_utils as vis_util

class ObjectDetectionNode():
    def __init__(self):
        NUM_CLASSES = 90
        self.bridge = CvBridge()
        self.model = rospy.get_param("~model")
        self.labels = rospy.get_param("~labels")
        self.category_list = rospy.get_param("/category_list")
        # Create color for each category
        self.color_map = []
        for c in self.category_list:
            color = np.random.randint(0, 255, size=(3,))
            color = (int(color[0]), int(color[1]), int(color[2]))
            self.color_map.append(color)
        self.min_score_threshold = rospy.get_param("~min_score_threshold")
        self.image_topic = rospy.get_param("~image_topic")
        self.object_image_topic = rospy.get_param("~object_image_topic")
        self.object_array_topic = rospy.get_param("~object_array_topic")
        # Load the label map.
        # Label maps map indices to category names, so that when the convolution
        # network predicts `5` we know that this corresponds to `airplane`.
        # Here we use internal utility functions, but anything that returns a
        # dictionary mapping integers to appropriate string labels would be fine.
        self.label_map = label_map_util.load_labelmap(self.labels)
        self.categories = label_map_util.convert_label_map_to_categories(self.label_map, max_num_classes=NUM_CLASSES, use_display_name=True)
        self.category_index = label_map_util.create_category_index(self.categories)
        # Load tensorflow model into memory
        self.detection_graph = self.loadGraph()
        # Input tensor is the image
        self.image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')
        # Output tensors are the detection boxes, scores and classes
        # Each box represents a part of the image where a particular object was detected
        self.detection_boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')
        # Each score represents level of confidence for each of the objects.
        # The score is shown on the result image, together with the class label.
        self.detection_scores = self.detection_graph.get_tensor_by_name('detection_scores:0')
        self.detection_classes = self.detection_graph.get_tensor_by_name('detection_classes:0')
        # Number of objects detected
        self.num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')
        # Subscribe to the image topic
        self.image_sub = rospy.Subscriber(self.image_topic, Image, self.callback)
        # Output the detection image
        self.object_image_pub = rospy.Publisher(self.object_image_topic, Image, queue_size=1)
        # Output the list of detected objects
        self.object_array_pub = rospy.Publisher(self.object_array_topic, ObjectArray, queue_size=1)
        rospy.spin()


    def loadGraph(self):
        detection_graph = tf.Graph()
        with detection_graph.as_default():
            od_graph_def = tf.compat.v1.GraphDef()
            with tf.io.gfile.GFile(self.model, 'rb') as fid:
                serialized_graph = fid.read()
                od_graph_def.ParseFromString(serialized_graph)
                tf.import_graph_def(od_graph_def, name='')
            self.sess = tf.compat.v1.Session(graph=detection_graph)
        return detection_graph

    def callback(self, data):
        try:
            frame = self.bridge.imgmsg_to_cv2(data, "bgr8")
            im_height, im_width, im_channels = frame.shape
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame_expanded = np.expand_dims(frame_rgb, axis=0)

            # Perform the actual detection by running the model with the image as input
            (boxes, scores, classes, num) = self.sess.run(
                [self.detection_boxes, self.detection_scores, self.detection_classes, self.num_detections],
                feed_dict={self.image_tensor: frame_expanded})


            msg = ObjectArray()
            msg.header.frame_id = data.header.frame_id
            msg.header.stamp = data.header.stamp
            boxes = np.squeeze(boxes)
            classes = np.squeeze(classes).astype(np.int32)
            scores = np.squeeze(scores)
            for (obj_box, obj_class, obj_score) in zip(boxes, classes, scores):
                category = self.category_index[obj_class]['name']
                if obj_score > self.min_score_threshold and category in self.category_list:
                    # Box coordinates are normalized (between 0 and 1)
                    ymin, xmin, ymax, xmax = tuple(obj_box)
                    xmin *= im_width
                    xmax *= im_width
                    ymin *= im_height
                    ymax *= im_height
                    obj = Object()
                    obj.score = obj_score
                    obj.category = self.category_index[obj_class]['name']
                    obj.box.x = xmin
                    obj.box.y = ymin
                    obj.box.width = xmax - xmin
                    obj.box.height = ymax - ymin
                    color_index = self.category_list.index(obj.category)
                    color = self.color_map[color_index]
                    tl = (int(xmin), int(ymin))
                    br = (int(xmax), int(ymax))
                    label = "{}: {:.2f}".format(obj.category, obj.score)
                    cv2.putText(frame, label, tl, cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)
                    cv2.rectangle(frame, tl, br, color, 4)
                    msg.objects.append(obj)
            self.object_array_pub.publish(msg)

            # Draw the results of the detection (aka 'visulaize the results')
            #vis_util.visualize_boxes_and_labels_on_image_array(
            #    frame,
            #    np.squeeze(boxes),
            #    np.squeeze(classes).astype(np.int32),
            #    np.squeeze(scores),
            #    self.category_index,
            #    use_normalized_coordinates=True,
            #    line_thickness=8,
            #    min_score_thresh=0.40)

            # Publish the detected object on the image
            self.object_image_pub.publish(self.bridge.cv2_to_imgmsg(frame))

        except CvBridgeError as e:
            print(e)


if __name__ == '__main__':
    # Initialize the node and name it
    rospy.init_node('object_detection_node')
    try:
        object_detection_node = ObjectDetectionNode()
    except rospy.ROSInterruptException: pass
